# Pix2Pix-B-W-to-Color-VLG-Summer
VLG Summer Project 2022

## Usage

- Open the pix2pix jupyter notebook on Google Colab.
- Select GPU in runtime Type and then hit connect.
- Run the first 2 Commands downloading the dataset into root or you can go forward with the dataset of your choice making changes accordingly.
- within the directory of the dataset named coco_sample, create an Output and a train folder, Output, as the name suggests will store the output and train will store the B/W images that come from the RGB images present in our dataset.
- Once that is done you can run the rest of the commands and start training your model.
- The result after training ~4000 images for 25 epochs was descent enough(images present below) and also helped out with time constraints.

## Generated Outputs(Results):
Real Images were not a part of the dataset and were captured in grayscale originally:

![Screenshot (244)](https://user-images.githubusercontent.com/76242511/176699376-0222e55d-7cb6-4b54-9e62-06fdd5222bfd.png)
